---
title: "Transformer-based Bayesian Optimization"
collection: research_experiences
type: "Bachelor's Project"
index: 1
excerpt: "<b>Abstract:</b> 
<br>&nbsp; &nbsp;  &nbsp; Bayesian optimization is widely used for black-box function optimization, excelling in global optimization and minimal sample requirements. It is valuable for complex, non-convex, and computationally expensive problems, prevalent in machine learning and optimization. Traditional Bayesian optimization relies on Gaussian processes, which face limitations in computational cost and scalability. Noticing Transformer's strong ability in sequential decision-making problems, we proposes a Transformer-based Bayesian optimization approach, <b>merging Bayesian Optimization's applicability on various kinds of data with neural network scalability</b>. This approach, incorporating self-attention mechanisms for better contextual integration, <b>outperforms traditional methods</b>, delivering similar optimization performance as Gaussian processes but with significantly <b>faster processing times and lower complexity (O(n<sup>1.41</sup>)</b> for PT-BO and O(n<sup>2.16</sup>) for GP-BO). Moreover, experiments show Transformer-based Bayesian optimization to be <b>more efficient for high-dimensional data or large datasets</b>, with higher optimization efficiency compared to GP-BO."
date: 2023-06-24
date_show: "2023"
# venue: 'IEEE Transactions on Image Processing vol.31'
# paperurl: 'https://ieeexplore.ieee.org/document/9776607'
citation: '<i>Advisor: <br>Yilin Mo, Associate Professor, Department of Automation, THU <br>Yanan Sui, Associate Professor, Department of Aerospace Engineering, THU</i>' 
img: "/images/TransformerBO.png"
---